# Importiamo le librerie necessarie
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import f1_score, precision_score, recall_score
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import string
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional

# Monta Google Drive (solo per Google Colab)
from google.colab import drive
drive.mount('/content/drive')

# Imposta il percorso del file CSV su Google Drive
file_path = '/content/drive/MyDrive/Filter_Toxic_Comments_dataset.csv'  # Modifica con il percorso corretto

# Verifica se il file esiste nella directory specificata
import os
if os.path.exists(file_path):
    print(f"File trovato: {file_path}")
else:
    print(f"File non trovato nel percorso: {file_path}")

# Caricamento del dataset
df = pd.read_csv(file_path)

# Esplorazione del dataset
print(df.head())  # Prime righe
print(df.describe())  # Statistiche descrittive
print(df.isnull().sum())  # Valori mancanti

# Analisi della distribuzione delle etichette
labels = df.drop(columns=['comment'])
label_distribution = labels.sum(axis=0)
print("Distribuzione delle etichette:", label_distribution)

# Lunghezza media dei commenti
texts = df['comment']
comment_lengths = texts.apply(lambda x: len(x.split()))
print("Lunghezza media dei commenti:", comment_lengths.mean())

# Preprocessing testuale: rimozione di stopwords e lemmatizzazione
def preprocess_text(text):
    # Rimuovere punteggiatura
    text = ''.join([char for char in text if char not in string.punctuation])
    # Rimozione di stopwords e lemmatizzazione
    stop_words = set(stopwords.words('italian'))
    lemmatizer = WordNetLemmatizer()
    text = ' '.join([lemmatizer.lemmatize(word.lower()) for word in text.split() if word.lower() not in stop_words])
    return text

texts = texts.apply(preprocess_text)  # Preprocessiamo i commenti

# Tokenizzazione dei commenti e creazione delle etichette binarie multi-label
mlb = MultiLabelBinarizer()
labels = df.drop(columns=['comment'])
y = mlb.fit_transform(labels.values)

# Suddivisione del dataset in training, validation e test
X_train, X_temp, y_train, y_temp = train_test_split(texts, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Tokenizzazione del testo
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

# Convertiamo i commenti in sequenze numeriche
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_val_seq = tokenizer.texts_to_sequences(X_val)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Calcoliamo la lunghezza massima delle sequenze
max_len = max([len(seq) for seq in X_train_seq])
print("Lunghezza massima delle sequenze:", max_len)

# Padding delle sequenze per avere una lunghezza uniforme
X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')
X_val_padded = pad_sequences(X_val_seq, maxlen=max_len, padding='post', truncating='post')
X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')

print("Shape del training set:", X_train_padded.shape)
print("Shape del test set:", X_test_padded.shape)

# Creazione del modello (LSTM bidirezionale)
model = Sequential()

# Layer di embedding per trasformare i numeri in vettori continui
model.add(Embedding(input_dim=10000, output_dim=128, input_length=max_len))

# Aggiungiamo un layer LSTM bidirezionale
model.add(Bidirectional(LSTM(128, return_sequences=False)))

# Aggiungiamo un layer dropout per prevenire overfitting
model.add(Dropout(0.5))

# Aggiungiamo i layer fully connected
model.add(Dense(128, activation='relu'))
model.add(Dense(y.shape[1], activation='sigmoid'))  # Usiamo sigmoid per la classificazione multi-label

# Compilazione del modello
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# Addestramento del modello
history = model.fit(X_train_padded, y_train,
                    validation_data=(X_val_padded, y_val),
                    epochs=5,
                    batch_size=64)

# Valutazione del modello sui dati di test
test_loss, test_acc = model.evaluate(X_test_padded, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_acc)

# Predizioni sul test set
y_pred = model.predict(X_test_padded)

# Applichiamo una soglia di 0.5 per determinare se una classe è presente o meno
y_pred_bin = (y_pred > 0.5).astype(int)

# Calcoliamo le metriche di performance per ogni classe
for i, label in enumerate(mlb.classes_):
    f1 = f1_score(y_test[:, i], y_pred_bin[:, i])
    precision = precision_score(y_test[:, i], y_pred_bin[:, i])
    recall = recall_score(y_test[:, i], y_pred_bin[:, i])
    print(f"Performance per la classe {label}:")
    print(f"  F1 Score: {f1:.4f}")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")

# Funzione per prevedere la tossicità su nuovi commenti
def predict_toxicity(new_comments):
    # Preprocessiamo il nuovo commento
    new_comments = [preprocess_text(comment) for comment in new_comments]
    new_comments_seq = tokenizer.texts_to_sequences(new_comments)
    new_comments_padded = pad_sequences(new_comments_seq, maxlen=max_len, padding='post', truncating='post')

    # Prediciamo la tossicità
    y_new_pred = model.predict(new_comments_padded)

    # Applicare la soglia per classificazione binaria
    y_new_pred_bin = (y_new_pred > 0.5).astype(int)

    # Convertiamo i risultati in etichette leggibili
    predictions = mlb.inverse_transform(y_new_pred_bin)

    return predictions

# Esempio di inferenza su nuovi commenti
new_comments = ["Questo è un commento innocente.", "Sei un idiota!"]
predictions = predict_toxicity(new_comments)
for comment, pred in zip(new_comments, predictions):
    print(f"Commento: {comment}")
    print(f"Predizioni: {pred}")
